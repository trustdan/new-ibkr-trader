# ğŸš€ IBKR Spread Automation - Comprehensive Master Plan

## ğŸ“‹ Executive Summary

This master plan details the development of an automated vertical spread options trading system for Interactive Brokers. Following vibe coding principles, we'll build a microservices architecture with Docker containers, creating a flow-state-preserving development experience while delivering a production-ready trading platform.

### Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Windows GUI Application                      â”‚
â”‚                   (Go Backend + Svelte Frontend)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                   â”‚
                 WebSocket            REST API
                      â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Docker Container Network                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Python IBKR Interface       â”‚      Go Scanner Engine         â”‚
â”‚        (ib-insync)              â”‚   (High-Performance)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                 TCP Socket
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
              â”‚   TWS/IB     â”‚
              â”‚   Gateway    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒŠ Phase 0: Foundation & Vibe Setup (5 Days)

### Day 1: Project Genesis & Vibe Initialization
**Morning (4 hours)**
```gherkin
Feature: Project Foundation Creation
  As a vibe-conscious developer
  I want to establish a project structure that promotes flow state
  So that development feels natural and productive

  Scenario: Initialize vibe-friendly repository
    Given I have an empty project directory
    When I create the foundational structure
    Then I have these directories:
      | Directory        | Purpose                           |
      | src/            | Clean production code             |
      | experiments/    | Safe playground for ideas         |
      | docs/           | Living documentation              |
      | .vibe/          | Flow logs and inspiration         |
      | flow_journal/   | Daily development insights        |
      | docker/         | Container configurations          |
      | tests/          | Test suites                       |
    And I have essential files:
      | File            | Content                           |
      | .gitignore      | Proper exclusions                 |
      | LICENSE         | MIT License                       |
      | CHANGELOG.md    | Version history template          |
      | IDEAS.md        | Future feature brainstorming      |
      | ADR/            | Architecture decisions            |
```

**Afternoon (4 hours)**
- Create `.vibe/templates/` with reusable code snippets
- Set up `flow_journal/template.md` for daily entries
- Initialize git repository with meaningful first commit
- Create `experiments/sandbox/` for quick prototypes
- Document project philosophy in `.vibe/manifesto.md`

### Day 2: Docker Environment Architecture
**Morning (4 hours)**
```gherkin
Feature: Containerized Development Environment
  As a developer
  I want isolated, reproducible service containers
  So that development is consistent across environments

  Scenario: Create Python IBKR container
    Given I need to connect to TWS API
    When I create docker/python-ibkr/Dockerfile
    Then it includes:
      | Component           | Version/Config                    |
      | Base Image         | python:3.11-slim                  |
      | ib-insync          | 0.9.86                           |
      | asyncio support    | Built-in                         |
      | Health check       | TWS connection status            |
    And environment variables:
      | Variable           | Default                           |
      | TWS_HOST          | host.docker.internal              |
      | TWS_PORT          | 7497                              |
      | CLIENT_ID         | 1                                 |
      | ENABLE_WATCHDOG   | true                              |

  Scenario: Create Go scanner container
    Given I need high-performance scanning
    When I create docker/go-scanner/Dockerfile
    Then it includes:
      | Component          | Version/Config                    |
      | Base Image        | golang:1.21-alpine               |
      | Build Stage       | Multi-stage for tiny image       |
      | Concurrency       | GOMAXPROCS optimized             |
```

**Afternoon (4 hours)**
- Create `docker/gui/Dockerfile` for Windows app development
- Write `docker-compose.yml` with service orchestration
- Configure inter-container networking
- Set up volume mounts for hot-reloading
- Create `.env.example` for configuration

### Day 3: Documentation Framework & TWS Setup Guide
**Morning (4 hours)**
```gherkin
Feature: Comprehensive Documentation System
  As a future developer (including future me)
  I want clear, living documentation
  So that I can understand and extend the system

  Scenario: Create TWS configuration guide
    Given TWS has specific requirements
    When I document setup procedures
    Then docs/setup/TWS_CONFIGURATION.md includes:
      | Section                  | Details                      |
      | Global Configuration     | Enable Socket Clients        |
      | API Settings            | Disable Read-Only mode       |
      | Memory Allocation       | 4GB recommended              |
      | Auto-restart Time       | Configure for maintenance    |
      | Port Configuration      | 7497 (paper), 7496 (live)   |
      | Trusted IPs            | Whitelist configuration      |
```

**Afternoon (4 hours)**
- Create `docs/architecture/` with system design docs
- Write `docs/api/` templates for service documentation
- Set up `docs/deployment/` for production guides
- Initialize `ADR/001-docker-architecture.md`
- Create quick-start guide in `docs/QUICKSTART.md`

### Day 4: Development Tools & Scripts
**Morning (4 hours)**
- Create `scripts/dev-setup.sh` for environment initialization
- Write `scripts/health-check.py` for service monitoring
- Build `scripts/generate-docs.sh` for automated documentation
- Create `Makefile` with common commands

**Afternoon (4 hours)**
```bash
# Create development helper scripts
make dev          # Start development environment
make test         # Run all test suites
make lint         # Run linters
make build        # Build production images
make clean        # Clean up resources
```

### Day 5: Environment Validation & Flow Check
**Morning (4 hours)**
```gherkin
Feature: Development Environment Validation
  As a developer
  I want to verify my environment is properly configured
  So that I can begin productive development

  Scenario: Validate Docker setup
    Given I have completed environment setup
    When I run validation tests
    Then all containers start successfully
    And health checks pass
    And inter-container communication works
    And TWS connection requirements are documented
```

**Afternoon (4 hours)**
- First flow journal entry documenting setup experience
- Update IDEAS.md with initial feature thoughts
- Create `experiments/connection-test/` for TWS testing
- Document any setup pain points for improvement
- Prepare Phase 1 work breakdown

---

## ğŸ”Œ Phase 1: IBKR Connection Layer (10 Days)

### Day 6-7: Basic TWS Connection
**Day 6 Morning (4 hours)**
```gherkin
Feature: TWS Connection Foundation
  As the Python IBKR service
  I want to establish a reliable TWS connection
  So that I can execute trading operations

  Scenario: Initial connection establishment
    Given TWS is running with proper configuration
    When I start the Python container
    Then I connect using these steps:
      | Step | Action                          | Validation                |
      | 1    | Create IB() instance           | Object initialized        |
      | 2    | Set clientId=1                 | Unique ID assigned        |
      | 3    | Connect to host:7497           | Socket established        |
      | 4    | Start EReader thread           | Messages flow             |
      | 5    | Implement callbacks            | Events received           |
```

**Day 6 Afternoon (4 hours)**
```python
# src/python/core/connection.py
class IBKRConnection:
    """Manages TWS connection with automatic recovery"""
    
    def __init__(self, host='host.docker.internal', port=7497, client_id=1):
        self.ib = IB()
        self.watchdog = None
        self.connected = False
        
    async def connect(self):
        """Establish connection with retry logic"""
        # Implementation with error handling
        
    def setup_watchdog(self):
        """Configure automatic reconnection"""
        # Watchdog implementation
```

**Day 7 Morning (4 hours)**
- Implement connection error handling (Error 502, 507, 1100)
- Create connection state management
- Add comprehensive logging
- Build connection health endpoint

**Day 7 Afternoon (4 hours)**
```gherkin
Scenario: Handle daily TWS restart
  Given TWS restarts at 11:45 PM EST daily
  When the restart window approaches
  Then the system:
    | Action                     | Timing                |
    | Log pending restart       | 11:40 PM              |
    | Gracefully disconnect     | 11:44 PM              |
    | Enter waiting state       | 11:45 PM              |
    | Attempt reconnection      | 11:50 PM              |
    | Restore subscriptions     | Upon connection       |
```

### Day 8-9: Rate Limiting & Request Management
**Day 8 Morning (4 hours)**
```python
# src/python/core/rate_limiter.py
class RateLimiter:
    """Ensures compliance with TWS API rate limits"""
    
    def __init__(self, max_requests_per_second=45):
        self.rate_limit = max_requests_per_second
        self.request_queue = asyncio.Queue()
        self.request_times = deque(maxlen=50)
        
    async def execute_request(self, request_func, *args, **kwargs):
        """Execute request with rate limiting"""
        await self._wait_if_needed()
        return await request_func(*args, **kwargs)
```

**Day 8 Afternoon (4 hours)**
- Implement request queuing system
- Add pacing violation recovery (Error 100)
- Create request batching for efficiency
- Build metrics collection for monitoring

**Day 9 Morning (4 hours)**
```gherkin
Feature: Intelligent Request Management
  As the IBKR service
  I want to optimize API requests
  So that I maximize throughput without violations

  Scenario: Batch similar requests
    Given I have multiple contract lookups
    When requests are similar
    Then I batch them together
    And execute within rate limits
    
  Scenario: Handle pacing violations
    Given I receive Error 100
    When the error occurs
    Then I implement exponential backoff
    And reduce request rate temporarily
    And gradually increase to normal
```

**Day 9 Afternoon (4 hours)**
- Test rate limiting under load
- Document request patterns
- Create performance benchmarks
- Update flow journal with insights

### Day 10-11: Market Data Streaming
**Day 10 Morning (4 hours)**
```python
# src/python/market_data/streaming.py
class MarketDataManager:
    """Manages real-time market data subscriptions"""
    
    def __init__(self, ib_connection, cache_ttl=60):
        self.ib = ib_connection
        self.subscriptions = {}
        self.data_cache = TTLCache(maxsize=10000, ttl=cache_ttl)
        
    async def subscribe_option_chain(self, underlying, exchange='SMART'):
        """Subscribe to full option chain data"""
        # Implementation with caching
        
    async def get_option_greeks(self, contract):
        """Fetch real-time Greeks with caching"""
        # Greeks calculation and caching
```

**Day 10 Afternoon (4 hours)**
- Implement option chain retrieval
- Add Greeks calculation pipeline
- Create data caching layer
- Handle subscription limits

**Day 11 Morning (4 hours)**
```gherkin
Feature: Efficient Market Data Management
  As a data consumer
  I want optimized market data access
  So that I minimize API calls and costs

  Scenario: Cache frequently accessed data
    Given I request SPY option chain
    When the data is retrieved
    Then it's cached for 60 seconds
    And subsequent requests use cache
    
  Scenario: Manage subscription limits
    Given TWS has line limits per subscription
    When approaching limits
    Then I prioritize active contracts
    And unsubscribe from stale data
```

**Day 11 Afternoon (4 hours)**
- Test data streaming performance
- Optimize cache hit rates
- Document data patterns
- Create data flow diagrams

### Day 12-13: Order Execution Engine
**Day 12 Morning (4 hours)**
```python
# src/python/trading/order_engine.py
class OrderExecutionEngine:
    """Handles order placement and monitoring"""
    
    async def place_vertical_spread(self, legs, order_type='LMT'):
        """Place a vertical spread combo order"""
        combo = self._create_combo_contract(legs)
        order = self._create_combo_order(order_type)
        
        # Preview with whatIfOrder
        preview = await self.ib.whatIfOrderAsync(combo, order)
        
        if self._validate_preview(preview):
            trade = await self.ib.placeOrderAsync(combo, order)
            return self._monitor_order(trade)
```

**Day 12 Afternoon (4 hours)**
- Implement combo order creation
- Add OCA group management
- Create order validation logic
- Build order status monitoring

**Day 13 Morning (4 hours)**
```gherkin
Feature: Reliable Order Execution
  As a trader
  I want confident order execution
  So that my spreads are filled correctly

  Scenario: Execute debit spread
    Given I have selected spread legs
    When I submit the order
    Then the system:
      | Step              | Action                    |
      | Preview          | whatIfOrder validation     |
      | Risk Check       | Margin/capital validation  |
      | Submit           | Place combo order          |
      | Monitor          | Track fill status          |
      | Confirm          | Log execution details      |
```

**Day 13 Afternoon (4 hours)**
- Test order execution flows
- Implement fill monitoring
- Add execution reporting
- Document order types supported

### Day 14-15: Integration Testing & Hardening
**Day 14 (8 hours)**
- Create comprehensive integration tests
- Test connection recovery scenarios
- Validate rate limiting under stress
- Ensure order execution reliability

**Day 15 (8 hours)**
- Performance optimization
- Update documentation
- Flow journal reflection
- Prepare scanner integration

---

## âš¡ Phase 2: Go Scanner Engine (10 Days)

### Day 16-17: Scanner Architecture
**Day 16 Morning (4 hours)**
```go
// src/go/scanner/core/scanner.go
package core

type Scanner struct {
    filters     []Filter
    dataSource  DataSource
    results     chan ScanResult
    workers     int
}

type Filter interface {
    Apply(contracts []Contract) []Contract
    Name() string
}

type ScanRequest struct {
    Underlying   string
    FilterConfig FilterConfiguration
}
```

**Day 16 Afternoon (4 hours)**
```gherkin
Feature: High-Performance Options Scanner
  As a trader
  I want lightning-fast option scanning
  So that I can identify opportunities quickly

  Scenario: Concurrent scanning architecture
    Given I have 50 underlying symbols
    When I initiate scanning
    Then the scanner:
      | Component        | Behavior                  |
      | Worker Pool      | 10 concurrent workers     |
      | Channel Buffer   | 1000 results             |
      | Memory Pool      | Reusable allocations     |
      | Result Stream    | Non-blocking delivery    |
```

**Day 17 Morning (4 hours)**
- Implement worker pool pattern
- Create filter interface system
- Build result aggregation
- Add performance metrics

**Day 17 Afternoon (4 hours)**
```go
// src/go/scanner/filters/delta.go
type DeltaFilter struct {
    MinDelta float64
    MaxDelta float64
}

func (f *DeltaFilter) Apply(contracts []Contract) []Contract {
    // Efficient filtering implementation
}

// Similar implementations for all filter types
```

### Day 18-19: Core Filter Implementation
**Day 18 Morning (4 hours)**
```gherkin
Feature: Comprehensive Filter Suite
  As a trader
  I want all standard option filters
  So that I can implement any strategy

  Scenario: Apply multiple filters
    Given I configure these filters:
      | Filter Type      | Configuration        |
      | Delta           | 0.25 - 0.35         |
      | DTE             | 30 - 60             |
      | Volume          | Min 100             |
      | Bid-Ask Spread  | Max 0.10            |
      | IV Percentile   | Min 50              |
    When scanning executes
    Then only matching contracts pass
    And performance remains sub-100ms
```

**Day 18 Afternoon (4 hours)**
- Implement Greeks filters (delta, gamma, theta, vega)
- Add liquidity filters (volume, open interest)
- Create DTE and expiration filters
- Build spread width calculations

**Day 19 Morning (4 hours)**
```go
// src/go/scanner/filters/advanced.go
type IVPercentileFilter struct {
    MinPercentile float64
    LookbackDays  int
}

type ProbabilityFilter struct {
    MinPoP float64
    MaxITM float64
}

// Additional advanced filters
```

**Day 19 Afternoon (4 hours)**
- Implement IV-based filters
- Add probability calculations
- Create technical indicator filters
- Build composite filter chains

### Day 20-21: Data Integration Layer
**Day 20 Morning (4 hours)**
```go
// src/go/scanner/data/integration.go
type DataBridge struct {
    pythonAPI   *PythonAPIClient
    cache       *Cache
    updateChan  chan MarketUpdate
}

func (d *DataBridge) StreamOptionChains(symbols []string) {
    // Efficient streaming implementation
}
```

**Day 20 Afternoon (4 hours)**
- Connect to Python IBKR service
- Implement data transformation
- Add caching layer
- Create update channels

**Day 21 Morning (4 hours)**
```gherkin
Feature: Real-time Data Integration
  As the scanner
  I want live market data
  So that results are always current

  Scenario: Handle data updates
    Given market data is streaming
    When prices change
    Then scanner results update
    And stale results are purged
    And subscribers are notified
```

**Day 21 Afternoon (4 hours)**
- Test data flow performance
- Optimize memory usage
- Document data contracts
- Create integration tests

### Day 22-23: Scanner API & Optimization
**Day 22 Morning (4 hours)**
```go
// src/go/scanner/api/server.go
type ScannerAPI struct {
    scanner *core.Scanner
    server  *gin.Engine
}

// REST endpoints
// GET  /scan/start
// POST /scan/filters
// GET  /scan/results
// WS   /scan/stream
```

**Day 22 Afternoon (4 hours)**
- Implement REST API
- Add WebSocket streaming
- Create API documentation
- Build client SDK

**Day 23 Morning (4 hours)**
```gherkin
Feature: Scanner Performance Optimization
  As a performance-critical component
  I want maximum efficiency
  So that scanning never becomes a bottleneck

  Scenario: Optimize for large datasets
    Given 10,000+ option contracts
    When applying 15 filters
    Then results return in <100ms
    And memory usage stays <500MB
    And CPU usage is distributed
```

**Day 23 Afternoon (4 hours)**
- Profile and optimize hot paths
- Implement result pagination
- Add benchmark suite
- Document performance characteristics

### Day 24-25: Testing & Polish
**Day 24 (8 hours)**
- Comprehensive unit tests
- Integration testing with Python service
- Load testing with realistic data
- Error handling verification

**Day 25 (8 hours)**
- Code review and refactoring
- Performance documentation
- API usage examples
- Flow journal insights

---

## ğŸ–¥ï¸ Phase 3: GUI Development (15 Days)

### Day 26-28: GUI Architecture & Setup
**Day 26 Morning (4 hours)**
```gherkin
Feature: Desktop Application Foundation
  As a Windows user
  I want a native-feeling application
  So that trading feels natural and responsive

  Scenario: Application structure
    Given I need a desktop GUI
    When I design the architecture
    Then I have:
      | Component         | Technology          |
      | Backend          | Go + Gin           |
      | Frontend         | Svelte + Vite      |
      | Desktop Wrapper  | Electron or Wails  |
      | State Management | Svelte stores      |
      | UI Library       | Custom + Tailwind  |
```

**Day 26 Afternoon (4 hours)**
```javascript
// src/gui/frontend/src/lib/stores/trading.js
import { writable, derived } from 'svelte/store';

export const scannerConfig = writable({
    filters: {
        delta: { min: 0.25, max: 0.35 },
        dte: { min: 30, max: 60 },
        // ... other filters
    }
});

export const scanResults = writable([]);
export const selectedSpread = writable(null);
```

**Day 27 Morning (4 hours)**
- Set up Svelte project with Vite
- Configure Go backend server
- Implement WebSocket client
- Create store architecture

**Day 27 Afternoon (4 hours)**
```svelte
<!-- src/gui/frontend/src/components/FilterPanel.svelte -->
<script>
    import { scannerConfig } from '$lib/stores/trading';
    import DeltaFilter from './filters/DeltaFilter.svelte';
    import DTEFilter from './filters/DTEFilter.svelte';
    // ... other filter imports
</script>

<div class="filter-panel">
    <h2>Scanner Filters</h2>
    <DeltaFilter bind:config={$scannerConfig.filters.delta} />
    <DTEFilter bind:config={$scannerConfig.filters.dte} />
    <!-- Additional filters -->
</div>
```

**Day 28 Morning (4 hours)**
- Create main application layout
- Build navigation system
- Implement theme system
- Add responsive design

**Day 28 Afternoon (4 hours)**
- Set up build pipeline
- Configure hot reloading
- Create component library
- Document UI patterns

### Day 29-31: Parameter Control Interface
**Day 29 Morning (4 hours)**
```gherkin
Feature: Intuitive Parameter Controls
  As a trader
  I want easy-to-use controls
  So that I can quickly adjust my strategy

  Scenario: Delta range slider
    Given I need to set delta range
    When I use the dual slider
    Then I can:
      | Action              | Result                |
      | Drag min handle     | Updates minimum      |
      | Drag max handle     | Updates maximum      |
      | Click on track      | Moves nearest handle |
      | Type in input       | Precise value entry  |
```

**Day 29 Afternoon (4 hours)**
```svelte
<!-- src/gui/frontend/src/components/filters/DeltaFilter.svelte -->
<script>
    export let config = { min: 0.25, max: 0.35 };
    
    function handleUpdate(event) {
        // Real-time validation and update
    }
</script>

<div class="filter-container">
    <label>Delta Range</label>
    <RangeSlider 
        bind:values={[config.min, config.max]}
        min={0} 
        max={1} 
        step={0.05}
        on:change={handleUpdate}
    />
    <div class="input-group">
        <input type="number" bind:value={config.min} min="0" max="1" step="0.05">
        <span>to</span>
        <input type="number" bind:value={config.max} min="0" max="1" step="0.05">
    </div>
</div>
```

**Day 30 Morning (4 hours)**
- Implement all filter components
- Create validation system
- Add tooltips and help text
- Build preset management

**Day 30 Afternoon (4 hours)**
```gherkin
Feature: Filter Presets
  As a trader with multiple strategies
  I want to save filter configurations
  So that I can quickly switch strategies

  Scenario: Save current configuration
    Given I have configured my filters
    When I click "Save Preset"
    Then I can name it "High IV Strategy"
    And it saves all current settings
    And appears in preset dropdown
```

**Day 31 Morning (4 hours)**
- Create preset save/load system
- Implement profile management
- Add import/export functionality
- Build quick-access toolbar

**Day 31 Afternoon (4 hours)**
- Test all parameter controls
- Ensure 3-click navigation
- Polish UI interactions
- Document control behaviors

### Day 32-34: Real-time Data Visualization
**Day 32 Morning (4 hours)**
```svelte
<!-- src/gui/frontend/src/components/ScannerResults.svelte -->
<script>
    import { scanResults } from '$lib/stores/trading';
    import VirtualList from '@tanstack/svelte-virtual';
    
    $: sortedResults = $scanResults.sort((a, b) => b.score - a.score);
</script>

<div class="results-grid">
    <VirtualList 
        data={sortedResults}
        estimateSize={50}
        overscan={5}
    >
        {#each virtualItems as item}
            <ResultRow result={item} />
        {/each}
    </VirtualList>
</div>
```

**Day 32 Afternoon (4 hours)**
- Implement virtual scrolling
- Add real-time updates
- Create sorting system
- Build column customization

**Day 33 Morning (4 hours)**
```gherkin
Feature: Live Scanner Visualization
  As a trader
  I want to see results as they arrive
  So that I can act on opportunities quickly

  Scenario: Real-time result updates
    Given scanner is running
    When new results arrive
    Then they appear immediately
    And maintain sort order
    And highlight recent changes
    And show update animations
```

**Day 33 Afternoon (4 hours)**
- Add result highlighting
- Implement Greeks display
- Create mini charts
- Build detail panels

**Day 34 Morning (4 hours)**
- Add position tracking view
- Create P&L dashboard
- Implement trade history
- Build performance metrics

**Day 34 Afternoon (4 hours)**
- Test data visualization
- Optimize rendering performance
- Add export capabilities
- Document visualization patterns

### Day 35-37: Trade Execution Interface
**Day 35 Morning (4 hours)**
```svelte
<!-- src/gui/frontend/src/components/TradeExecution.svelte -->
<script>
    import { selectedSpread } from '$lib/stores/trading';
    import OrderPreview from './OrderPreview.svelte';
    
    async function executeSpread() {
        const preview = await api.previewOrder($selectedSpread);
        // Show preview dialog
    }
</script>

<div class="execution-panel">
    <SpreadVisualizer spread={$selectedSpread} />
    <OrderParameters />
    <OrderPreview />
    <button on:click={executeSpread}>Execute Spread</button>
</div>
```

**Day 35 Afternoon (4 hours)**
- Create spread visualizer
- Build order preview
- Add risk calculations
- Implement confirmation flow

**Day 36 Morning (4 hours)**
```gherkin
Feature: Safe Trade Execution
  As a trader
  I want clear execution confirmation
  So that I never place unintended trades

  Scenario: Execute vertical spread
    Given I select a spread opportunity
    When I click execute
    Then I see:
      | Information         | Display              |
      | Spread legs        | Strike prices/dates  |
      | Max risk           | Dollar amount        |
      | Max profit         | Dollar amount        |
      | Breakeven          | Price level          |
      | Margin required    | From whatIfOrder     |
    And I must confirm before submission
```

**Day 36 Afternoon (4 hours)**
- Implement whatIfOrder preview
- Add margin impact display
- Create position sizing tool
- Build order modification

**Day 37 Morning (4 hours)**
- Add order status tracking
- Implement fill notifications
- Create execution log
- Build error handling

**Day 37 Afternoon (4 hours)**
- Test execution flows
- Add keyboard shortcuts
- Polish confirmations
- Document trade flow

### Day 38-40: Integration & Polish
**Day 38 (8 hours)**
- Connect all UI components
- Implement state persistence
- Add keyboard navigation
- Create help system

**Day 39 (8 hours)**
- Performance optimization
- Accessibility improvements
- Theme customization
- Settings management

**Day 40 (8 hours)**
- User acceptance testing
- Bug fixes and polish
- Create user guide
- Package application

---

## ğŸ”§ Phase 4: System Integration (10 Days)

### Day 41-42: Service Orchestration
**Day 41 Morning (4 hours)**
```yaml
# docker-compose.yml
version: '3.8'

services:
  python-ibkr:
    build: ./docker/python-ibkr
    environment:
      - TWS_HOST=host.docker.internal
      - TWS_PORT=7497
      - CLIENT_ID=1
    volumes:
      - ./src/python:/app
    healthcheck:
      test: ["CMD", "python", "/app/health_check.py"]
      interval: 30s
      
  go-scanner:
    build: ./docker/go-scanner
    depends_on:
      - python-ibkr
    environment:
      - IBKR_API_URL=http://python-ibkr:8000
    volumes:
      - ./src/go:/app
      
  gui-backend:
    build: ./docker/gui
    ports:
      - "3000:3000"
    depends_on:
      - go-scanner
    volumes:
      - ./src/gui:/app
```

**Day 41 Afternoon (4 hours)**
- Configure service discovery
- Implement health checks
- Set up logging aggregation
- Create monitoring stack

**Day 42 Morning (4 hours)**
```gherkin
Feature: Resilient Service Communication
  As a distributed system
  I want reliable inter-service communication
  So that the system remains stable

  Scenario: Handle service failures
    Given all services are running
    When python-ibkr becomes unavailable
    Then go-scanner enters degraded mode
    And GUI shows connection warning
    And system attempts reconnection
    And recovers when service returns
```

**Day 42 Afternoon (4 hours)**
- Implement circuit breakers
- Add retry logic
- Create fallback mechanisms
- Build service mesh

### Day 43-44: End-to-End Workflows
**Day 43 Morning (4 hours)**
```gherkin
Feature: Complete Trading Workflow
  As a trader
  I want seamless end-to-end functionality
  So that trading is efficient

  Scenario: Full trade execution
    Given I start the application
    When I configure scanners
    And identify opportunity
    And execute spread
    Then:
      | Step                 | System Action              |
      | Scanner runs        | Go service processes       |
      | Results stream      | WebSocket to GUI          |
      | User selects        | GUI sends to backend      |
      | Preview generated   | Python calls whatIfOrder  |
      | Order placed        | Python executes trade     |
      | Status updates      | Real-time to GUI          |
```

**Day 43 Afternoon (4 hours)**
- Test complete workflows
- Verify data flow
- Check error propagation
- Validate state management

**Day 44 (8 hours)**
- Integration test suite
- Performance testing
- Load testing
- Stress testing

### Day 45-46: Production Readiness
**Day 45 Morning (4 hours)**
- Create deployment scripts
- Configure production environment
- Set up monitoring alerts
- Build backup systems

**Day 45 Afternoon (4 hours)**
```gherkin
Feature: Production Deployment
  As an operations team
  I want reliable deployment
  So that updates are safe

  Scenario: Zero-downtime deployment
    Given system is running in production
    When deploying updates
    Then services update sequentially
    And connections remain stable
    And no orders are lost
```

**Day 46 (8 hours)**
- Security audit
- Performance optimization
- Documentation review
- Deployment dry run

### Day 47-50: Testing & Documentation
**Day 47-48 (16 hours)**
- Comprehensive system testing
- User acceptance testing
- Performance benchmarking
- Security testing

**Day 49-50 (16 hours)**
- Complete documentation
- Create video tutorials
- Write troubleshooting guide
- Prepare launch materials

---

## ğŸ“Š Success Metrics & Monitoring

### Performance Targets
```gherkin
Feature: System Performance Requirements
  As a production system
  I must meet performance targets
  So that traders can rely on the platform

  Scenario: Scanner performance
    Given 10,000 option contracts
    When applying 15 filters
    Then results return in <100ms
    
  Scenario: Order execution speed
    Given a spread order request
    When submitted to TWS
    Then confirmation in <1 second
    
  Scenario: GUI responsiveness
    Given any user action
    When processed
    Then UI responds in <50ms
```

### Monitoring Dashboard
- Real-time performance metrics
- API rate limit tracking
- Order execution success rate
- System health indicators
- Error rate monitoring

---

## ğŸš€ Beyond MVP: Future Enhancements

### Phase 5: Advanced Features (15 Days)
- Multi-leg strategies (Iron Condors, Butterflies)
- Advanced rolling logic
- Portfolio optimization
- Risk analytics dashboard

### Phase 6: Machine Learning (20 Days)
- Pattern recognition for opportunities
- Optimal parameter learning
- Performance prediction
- Automated strategy tuning

### Phase 7: Scale & Enterprise (20 Days)
- Multi-account support
- Team collaboration features
- Advanced audit trails
- Compliance reporting

---

## ğŸ“ Daily Development Rhythm

### Morning Ritual (30 min)
1. Read RULES.md for vibe check
2. Review TodoRead for current tasks
3. Check flow_journal for yesterday's insights
4. Set daily intention

### Development Flow (7 hours)
1. **Hour 1-2**: High-energy complex work
2. **Hour 3-4**: Implementation and testing
3. **Hour 5-6**: Integration and debugging
4. **Hour 7**: Documentation and cleanup

### Evening Reflection (30 min)
1. Update TodoWrite with progress
2. Commit with storytelling message
3. Quick flow_journal entry
4. Note ideas in IDEAS.md

---

## ğŸ¯ Project Success Checklist

### Technical Excellence
- [ ] Sub-second scanner performance
- [ ] 99.9% order execution reliability
- [ ] Zero pacing violations
- [ ] Smooth TWS restart handling
- [ ] Comprehensive error recovery

### User Experience
- [ ] 3-click navigation to any feature
- [ ] Intuitive parameter controls
- [ ] Real-time visual feedback
- [ ] Clear execution confirmations
- [ ] Helpful error messages

### Development Experience
- [ ] Maintained flow state
- [ ] Living documentation
- [ ] Clean code architecture
- [ ] Comprehensive testing
- [ ] Smooth deployment

---

This master plan provides a comprehensive 50-day initial development schedule with detailed daily work chunks. Each phase builds naturally upon the previous, maintaining vibe coding principles while delivering a production-ready automated trading system. The modular approach allows for adjustments based on discoveries during development while keeping the overall vision intact.